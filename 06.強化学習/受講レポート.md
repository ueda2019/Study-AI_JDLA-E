
深層学習day4 ビデオ受講 レポート（欠席のため）

# TensorFlowの基礎

```
DN63_講義全体の流れ － DN67_演習問題
```

- ソースコード：4_1_tensorflow_codes.py

## 基礎要素

### セッション

```python
sess = tf.Session()
```

- セッション作成/runがルーティーン
    - この前では、たとえ定数でも、Printしても中身は見れない

### 定数

```python
a = tf.constant(1)
```

- 固定値を定義

### プレースホルダー

```python
x = tf.placeholder(dtype=tf.float32, shape=[None,3])
...
sess.run(x, feed_dict={x:X[0].reshape(1,-1)})
```

- 箱を用意して、中身は後から
    - JDBCの「？」と同じ
- バッチごと代入などに使われる

### 変数

```python
# 変数の設定
x = tf.Variable(1)
calc_op = x * a
update_x = tf.assign(x, calc_op)
# 変数の初期化
init = tf.global_variables_initializer()
sess.run(init)
# 変数の更新
sess.run(update_x)
```

- 式をアサインすることで、あとから計算を実行して実値を生成


## 線形回帰の実装

### 式の構築

```python
# 入力値
xt = tf.placeholder(tf.float32, shape=[None,1])
dt = tf.placeholder(tf.float32, shape=[None,1])

# 最適化の対象の変数を初期化
W = tf.Variable(tf.zeros([1]))
b = tf.Variable(tf.zeros([1]))

y = W * xt + b

# 誤差関数 平均2乗誤差
loss = tf.reduce_mean(tf.square(y - dt))
optimizer = tf.train.GradientDescentOptimizer(0.1)
train = optimizer.minimize(loss)
```

### 学習


```python
for i in range(iters_num):
    sess.run(train, feed_dict={xt:x_train,dt:d_train})
    if (i+1) % plot_interval == 0:
        loss_val = sess.run(loss, feed_dict={xt:x_train,dt:d_train}) 
        W_val = sess.run(W)
        b_val = sess.run(b)
        print('Generation: ' + str(i+1) + '. 誤差 = ' + str(loss_val))
```


## 非線形回帰の実装


### 式の構築

```python
# Xに対する係数は４つになっている
xt = tf.placeholder(tf.float32, [None, 4])
dt = tf.placeholder(tf.float32, [None, 1])
W = tf.Variable(tf.random_normal([4, 1], stddev=0.01))
# 「Y = W * X」のこと
y = tf.matmul(xt,W)

loss = tf.reduce_mean(tf.square(y - dt))
# AdamOptimizerを使用
optimizer = tf.train.AdamOptimizer(0.001)
train = optimizer.minimize(loss)
```


### 学習


```python
for i in range(iters_num):
    if (i+1) % plot_interval == 0:
        loss_val = sess.run(loss, feed_dict={xt:x_train, dt:d_train}) 
        W_val = sess.run(W)
        print('Generation: ' + str(i+1) + '. 誤差 = ' + str(loss_val))
    sess.run(train, feed_dict={xt:x_train,dt:d_train})
```



# TensorFlowの応用

```
DN68_MNIST1 － DN70_MNIST3
```

- ソースコード：4_1_tensorflow_codes.py


## MNIST １層

### 式の構築

```python
# イメージサイズは28*28
x = tf.placeholder(tf.float32, [None, 784])
# 数字が0~9なので、10個
d = tf.placeholder(tf.float32, [None, 10])
W = tf.Variable(tf.random_normal([784, 10], stddev=0.01))
b = tf.Variable(tf.zeros([10]))
# softmax
y = tf.nn.softmax(tf.matmul(x, W) + b)
```

```python
# 分類なので、交差エントロピーを利用
cross_entropy = -tf.reduce_sum(d * tf.log(y), reduction_indices=[1])
loss = tf.reduce_mean(cross_entropy)
train = tf.train.GradientDescentOptimizer(0.1).minimize(loss)
```


### 学習

```python
for i in range(iters_num):
    x_batch, d_batch = mnist.train.next_batch(batch_size)
    sess.run(train, feed_dict={x: x_batch, d: d_batch})
    if (i+1) % plot_interval == 0:
        print(sess.run(correct, feed_dict={x: mnist.test.images, d: mnist.test.labels}))
        accuracy_val = sess.run(accuracy, feed_dict={x: mnist.test.images, d: mnist.test.labels})
        accuracies.append(accuracy_val)
        print('Generation: ' + str(i+1) + '. 正解率 = ' + str(accuracy_val))
```




## MNIST ３層



### 式の構築

```python
x = tf.placeholder(tf.float32, [None, 784])
d = tf.placeholder(tf.float32, [None, 10])

# 隠れ層を２つ足しこむ
W1 = tf.Variable(tf.random_normal([784, hidden_layer_size_1], stddev=0.01))
W2 = tf.Variable(tf.random_normal([hidden_layer_size_1, hidden_layer_size_2], stddev=0.01))
W3 = tf.Variable(tf.random_normal([hidden_layer_size_2, 10], stddev=0.01))
b1 = tf.Variable(tf.zeros([hidden_layer_size_1]))
b2 = tf.Variable(tf.zeros([hidden_layer_size_2]))
b3 = tf.Variable(tf.zeros([10]))

# 活性化
z1 = tf.sigmoid(tf.matmul(x, W1) + b1)
z2 = tf.sigmoid(tf.matmul(z1, W2) + b2)

# ドロップアウト
keep_prob = tf.placeholder(tf.float32)
drop = tf.nn.dropout(z2, keep_prob)

# 最終出力
y = tf.nn.softmax(tf.matmul(drop, W3) + b3)
loss = tf.reduce_mean(-tf.reduce_sum(d * tf.log(y), reduction_indices=[1]))
```

- 中間層の数や、層内のニューロンの数は、精度と時間のトレードオフで検討していく

### 学習

```python
for i in range(iters_num):
    x_batch, d_batch = mnist.train.next_batch(batch_size)
    sess.run(train, feed_dict={x:x_batch, d:d_batch, keep_prob:(1 - dropout_rate)})
    if (i+1) % plot_interval == 0:
        accuracy_val = sess.run(accuracy, feed_dict={x:mnist.test.images, d:mnist.test.labels, keep_prob:1.0})            
        accuracies.append(accuracy_val)
        print('Generation: ' + str(i+1) + '. 正解率 = ' + str(accuracy_val))        

```

- ドロップアウトの制御のみ追加


## MNIST CNN

- 以下の構成で層を構築
```
conv - relu - pool - conv - relu - pool - affin - relu - dropout - affin - softmax
```

### 式の構築

```python
# placeholder
x = tf.placeholder(tf.float32, shape=[None, 784])
d = tf.placeholder(tf.float32, shape=[None, 10])

# 画像を784の一次元から28x28の二次元に変換する
# 画像を28x28にreshape
x_image = tf.reshape(x, [-1,28,28,1])

# 第一層のweightsとbiasのvariable
W_conv1 = tf.Variable(tf.truncated_normal([5, 5, 1, 32], stddev=0.1))
b_conv1 = tf.Variable(tf.constant(0.1, shape=[32]))

# 第一層のconvolutionalとpool
# strides[0] = strides[3] = 1固定
h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1], padding='SAME') + b_conv1)
# プーリングサイズ n*n にしたい場合 ksize=[1, n, n, 1]
h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')

# 第二層
W_conv2 = tf.Variable(tf.truncated_normal([5, 5, 32, 64], stddev=0.1))
b_conv2 = tf.Variable(tf.constant(0.1, shape=[64]))
h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1, W_conv2, strides=[1, 1, 1, 1], padding='SAME') + b_conv2)
h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')

# 第一層と第二層でreduceされてできた特徴に対してrelu
W_fc1 = tf.Variable(tf.truncated_normal([7 * 7 * 64, 1024], stddev=0.1))
b_fc1 = tf.Variable(tf.constant(0.1, shape=[1024]))
h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])
h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)

# Dropout
keep_prob = tf.placeholder(tf.float32)
h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)

# 出来上がったものに対してSoftmax
W_fc2 = tf.Variable(tf.truncated_normal([1024, 10], stddev=0.1))
b_fc2 = tf.Variable(tf.constant(0.1, shape=[10]))
y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)
```

- 畳み込み層、プーリング層については、conv2d/max_poolなどライブラリの補助がある




# Keras

```
DN74_Keras1 － DN80_Keras7
```

- ソースコード：4_3_keras_codes.py


## 線形回帰

### モデルの構築

```python
# モデルを作成
model = Sequential()
# Dense＝全結合
model.add(Dense(input_dim=1, output_dim=1))

# モデルを表示
model.summary()

# モデルのコンパイル
model.compile(loss='mse', optimizer='sgd')

```

- Wもbはいらないし、変数やプレースホルダーもいらない


### モデルの学習

```python
for i in range(iters_num):
    loss = model.train_on_batch(x, d)
    if (i+1) % plot_interval == 0:
        print('Generation: ' + str(i+1) + '. 誤差 = ' + str(loss))

# パラメータを見ることもできる
W, b = model.layers[0].get_weights()
```


## 単純パーセプトロン

### モデルの構築

```python
model = Sequential()
model.add(Dense(input_dim=2, units=1))
model.add(Activation('sigmoid'))
model.summary()

model.compile(loss='binary_crossentropy', optimizer=SGD(lr=0.1))

```

### モデルの学習

```python
model.fit(X, T, epochs=30, batch_size=1)
```

- 通常for文で回す学習を、シンプルに書くことができる
- バッチサイズはGPUの関係で2の倍数にする


## 分類 iris


### モデルの構築

```python
#モデルの設定
model = Sequential()
model.add(Dense(12, input_dim=4))
model.add(Activation('relu'))
model.add(Dense(3, input_dim=12))
model.add(Activation('softmax'))
model.summary()

model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

```

- kerasなら、活性化もオプティマイザも、簡単に変更することができる
    - 活性化は、深いときはreluを使用した方が勾配消失しない

### モデルの学習

```python
history = model.fit(x_train, d_train, batch_size=5, epochs=20, verbose=1, validation_data=(x_test, d_test))

# テストデータ
loss = model.evaluate(x_test, d_test, verbose=0)
```


## 分類 mnist

### モデルの構築

```python
model = Sequential()
model.add(Dense(512, activation='relu', input_shape=(784,)))
model.add(Dropout(0.2))
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(10, activation='softmax'))
model.summary()

# one-hotなら、loss='categorical_crossentropy', 
model.compile(loss='sparse_categorical_crossentropy', 
              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), 
              metrics=['accuracy'])

```



### モデルの学習

```python
history = model.fit(x_train, d_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, d_test))
loss = model.evaluate(x_test, d_test, verbose=0)
```


## CNN分類 mnist

### モデルの構築

```python
model = Sequential()
# kernel_sizeはフィルタのサイズ
model.add(Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=input_shape))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(num_classes, activation='softmax'))
model.summary()

model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])
```

- Conv2D/MaxPooling2Dなどの層はライブラリが用意してくれている
- CNNなので、データは28ｘ28にreshapeしておく


### モデルの学習

```python
history = model.fit(x_train, d_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, d_test))

```



## CNN分類 cifar10

### モデルの構築

```python
model = Sequential()
 
model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))
model.add(Activation('relu'))
model.add(Conv2D(32, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
 
model.add(Conv2D(64, (3, 3), padding='same'))
model.add(Activation('relu'))
model.add(Conv2D(64, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
 
model.add(Flatten())
model.add(Dense(512))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(10))
model.add(Activation('softmax'))
 
# コンパイル
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])
```

- ニューラルネットワークに入れるデータの数値は、0-1に正規化しておく

### モデルの学習

```python
history = model.fit(x_train, d_train, epochs=20)

# モデルの永続化もできる
model.save('./CIFAR-10.h5')
```



## RNN 足し算

### モデルの構築

```python
model = Sequential()

model.add(SimpleRNN(units=16,
               return_sequences=True,
               input_shape=[8, 2],
               go_backwards=False,
               activation='relu',
               # dropout=0.5,
               # recurrent_dropout=0.3,
               # unroll = True,
            ))
# 出力層
model.add(Dense(1, activation='sigmoid', input_shape=(-1,2)))
model.summary()
model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.1), metrics=['accuracy'])
# model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])
```
- 層をSimpleRNNにするだけ
    - GRUやLSTMもある


### モデルの学習

```python
history = model.fit(x_bin, d_bin.reshape(-1, 8, 1), epochs=5, batch_size=2)
```




# 強化学習

```
DN81_強化学習１ － DN82_強化学習２
```

## 強化学習とは

- 長期的に報酬を最大化できるように、環境のなかで行動選択できるエージェントを作ること目標とする機械学習の一分野
- 行動の結果として与えられる利益(報酬)をもとに、行動を決定する原理を改善していく仕組み

## トレードオフ


- 環境について事前完璧な知識があれば、最適な行動を予測し決定することは可能
    - どのような顧客にキャンペーンメールを送信すると、どのような行動をかが既知である状況
- 強化学習の場合、上記仮定は成り立たない
    - 不完全な知識を元に行動しがら、データ収集
    - 最適な行動を見つけていく

- 探索と利用のトレードオフがある
    - 過去のデータで、ベストとされる行動のみを常に取り続けば、他にもっとベストな行動を見つけるこはできない
        - 探索が足りない状態
    - 未知の行動みを常に取り続ければ、過去経験が活かせない
        - 利用が足りない状態



## アーキテクチャ

- 環境
    - 状態を持ち、エージェントに観察される
- エージェント
    - 方策関数により、環境に行動を起こす
    - 環境から報酬を受け取り、価値関数で判定


- 価値関数
    - ある状態の価値に注目す場合は、状態価値関数
    - 状態と価値を組み合わせかたに注目する場合は、行動価値関数
- 方策関数
    - ある状態でどのような行動をとるのかの確率を与える関数



## 教師あり・なし学習との違い


- 強化学習と通常の教師あり・なし学習との違いは「目標」
- 教師なし・あり学習ではデータに含まれるパターンを見つけ出し、そのデータから予測することが目標
- 強化学習では、優れた方策を見つけることが目標


## 歴史

- 冬の時代があった、 計算速度進展により大規模な状態をもつ場合の強化学習を可能としつつある
- 関数近似法と、Q学習を組み合わせる手法の登場
    - Q学習
        - 行動価値関数を、行動する毎に更新することより学習を進める方法
    - 関数近似法
        - 価値関数や方策を関数近似する手法のこと


## 方策勾配法

- 方策反復法
    - 方策をモデル化して最適する手法 
- 方策勾配法
    - θ_(t+1) = θ_(t) + ε∇J(θ)
    - Jは「方策の良さ」で、定義しなければらい
- 方策定義方法
    - 平均報酬
    - 割引報酬和
    - 上記の定義に対応して、行動価値関数 :Q(s,a) :Q(s,a) の定義を行い、方策勾配定理が成り立つ




# 論文

```
DN71_論文, DN83_論文解説　DCGAN
```

## 論文実装

- 論文は、ネットで検索、無料で簡単に手に入る
    - architectureセクションが重要
    - アーカイブとしてPDFで見ることもできる
- 論文から実装してもいいし、github等で公開されているコードを使ってもよい
    - モデルが公開されていることもある

## 論文解説


- DCGAN
    - Deep Convolutional Generative Adversarial Networks
    - 生成系のネットワーク
    - GeneratorとDiscriminatorを戦わせる


# Kaggle

```
DN84_Kaggle － DN85_実践に繋がるインプット
```

- 世界的なAIの競技会を開催
- Googleが運営
- 実装を参照することもできる
- 参加は要登録
- Kernel、Discussionを参考にしながら＋α自分の工夫を積み上げる
- データサイズには気を付ける（マシンパワーと相談しながら）


# 例題

```
DN72_例題解説１ － DN72_例題解説２, DN82_強化学習２, DN83_論文解説　DCGAN
```

- GoogLenet インセプションモジュールについて
    - 答え：a
    - denseでなく、sparse
- GoogLenet Auxiliary Lossについて
    - 答え：a
    - 計算量を抑えるわけではない
- ResNetについて＝＞152層もある
    - 答え：あ：a
    - 答え：い：a
    - 答え：う：a
- 転移学習について
    - 答え：a
    - ワンショット学習は、転移学習と関係ない
- 物体検出アルゴリズムについて
    - 答え：a
- 強化学習 方策勾配について
     - 答え：a
     - 方策勾配定理がはいる
- GANについて
     - 答え：a
     - 0.5
- GAN 価値関数について
     - 答え：a
     - Dを最大化、Cを最小化
- GAN＋CNNについて
     - 答え：a
     - Leaky ReLU


